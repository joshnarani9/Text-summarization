{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = EntityRecognizer(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasa_core\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/09/3e02335c86be0e53fa2e621de8b9d9124c7372664b75cdefbc14b5014fc0/rasa_core-0.13.7-py3-none-any.whl\n",
      "Collecting rocketchat-API~=0.6.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/d4/fac143e4d2cc8729c189b25c2305fc21757a413565a5f30d9d8f2f1cfa5b/rocketchat_API-0.6.29-py3-none-any.whl\n",
      "Collecting fbmessenger~=5.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/cb/7c/1f13d2ef5d16588759c30a46ad0c83110cc59f1892f798f4d6f2e6d4d280/fbmessenger-5.5.0-py2.py3-none-any.whl\n",
      "Collecting python-socketio~=3.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/b5/db/dc823aa0b3397e52ebe8bba62ee39d6b9a088377809bc230d3ad2e5d2448/python_socketio-3.1.2-py2.py3-none-any.whl\n",
      "Collecting apscheduler~=3.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/93/09/ffc2ed85fa578cd0d4428e9c421407e5d91a4464bbaa44f789941416ae42/APScheduler-3.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx~=2.2 in c:\\josna\\lib\\site-packages (from rasa_core) (2.2)\n",
      "Requirement already satisfied: scikit-learn~=0.20.0 in c:\\josna\\lib\\site-packages (from rasa_core) (0.20.3)\n",
      "Collecting questionary>=1.0.1 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/be/3c/d57e96650318ab52f50030815cb34573ed6ba6056955fca12509827b12e4/questionary-1.1.0-py3-none-any.whl\n",
      "Collecting rasa-core-sdk~=0.12.1 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/75/47/4931e28176e28f9a66c537c93abe2d00b691be76fd06e1b96efd654c00b4/rasa_core_sdk-0.12.2-py2.py3-none-any.whl\n",
      "Collecting jsonpickle~=1.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
      "Collecting scipy~=1.2 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/f0/d00c0e01e077da883f030af3ff5ce653a0e9e4786f83faa89a6e18c98612/scipy-1.2.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting webexteamssdk~=1.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/30/c6/8e700b876e4cae92721569f579a36d8eee62e296c4813704e258a19f405c/webexteamssdk-1.1.1.tar.gz (48kB)\n",
      "Requirement already satisfied: packaging~=18.0 in c:\\josna\\lib\\site-packages (from rasa_core) (18.0)\n",
      "Requirement already satisfied: numpy~=1.16 in c:\\josna\\lib\\site-packages (from rasa_core) (1.16.2)\n",
      "Requirement already satisfied: jsonschema~=2.6 in c:\\josna\\lib\\site-packages (from rasa_core) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil~=2.7 in c:\\josna\\lib\\site-packages (from rasa_core) (2.7.5)\n",
      "Requirement already satisfied: requests~=2.20 in c:\\josna\\lib\\site-packages (from rasa_core) (2.21.0)\n",
      "Collecting twilio~=6.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/98/53c704069d13ce5d7b3642d36ab57929afbcd5f022879e3c16d395ee7dd0/twilio-6.26.0-py2.py3-none-any.whl\n",
      "Collecting python-telegram-bot~=11.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/6c/47932a4041ee76650ad1f45a80e1422077e1e99c08a4d7a61cfbe5393d41/python_telegram_bot-11.1.0-py2.py3-none-any.whl\n",
      "Collecting redis~=2.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing==1.0.5 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting pydot~=1.4 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting fakeredis~=0.10.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/bd/2756ddf350c4bb308e3255f9dcd6610f8b01344947bf74d5d166dc66b0a2/fakeredis-0.10.3-py2.py3-none-any.whl\n",
      "Collecting keras-applications==1.0.6 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl\n",
      "Collecting pykwalify~=1.7.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/9f/612de8ca540bd24d604f544248c4c46e9db76f6ea5eb75fb4244da6ebbf0/pykwalify-1.7.0-py2.py3-none-any.whl (40kB)\n",
      "Requirement already satisfied: tqdm~=4.0 in c:\\josna\\lib\\site-packages (from rasa_core) (4.28.1)\n",
      "Collecting pika~=0.12.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/48/72de47f63ba353bacd74b76bb65bc63620b0706d8b0471798087cd5a4916/pika-0.12.0-py2.py3-none-any.whl\n",
      "Collecting rasa-nlu~=0.14.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/53/31b6b14e124fa916c10e8e58d650cff57ace0027a9e69a0788b1afcc26f4/rasa_nlu-0.14.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: ruamel.yaml~=0.15.0 in c:\\josna\\lib\\site-packages (from rasa_core) (0.15.91)\n",
      "Requirement already satisfied: flask-cors~=3.0 in c:\\josna\\lib\\site-packages (from rasa_core) (3.0.7)\n",
      "Collecting pytz~=2018.9 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: typing~=3.0 in c:\\josna\\lib\\site-packages (from rasa_core) (3.6.6)\n",
      "Collecting coloredlogs~=10.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/0f/7877fc42fff0b9d70b6442df62d53b3868d3a6ad1b876bdb54335b30ff23/coloredlogs-10.0-py2.py3-none-any.whl\n",
      "Collecting terminaltables~=3.1 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 331, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 413, in read\n",
      "    data = self._fp.read(amt)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\josna\\lib\\http\\client.py\", line 447, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\josna\\lib\\http\\client.py\", line 491, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\josna\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\josna\\lib\\ssl.py\", line 1052, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\josna\\lib\\ssl.py\", line 911, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 143, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 318, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 102, in resolve\n",
      "    self._resolve_one(requirement_set, req)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 256, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 209, in _get_abstract_dist_for\n",
      "    self.require_hashes\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 283, in prepare_linked_requirement\n",
      "    progress_bar=self.progress_bar\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 836, in unpack_url\n",
      "    progress_bar=progress_bar\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 673, in unpack_http_url\n",
      "    progress_bar)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 897, in _download_http_url\n",
      "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 617, in _download_url\n",
      "    hashes.check_against_chunks(downloaded_chunks)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\utils\\hashes.py\", line 48, in check_against_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 585, in written_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_internal\\download.py\", line 574, in resp_read\n",
      "    decode_content=False):\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 465, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\josna\\lib\\contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\josna\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 336, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install rasa_core"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#####text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "te=\"\"\"So you see physical illness can have psychological causes. Now we just have time to introduce another interesting example of the interaction between the mind and the body. Placebos. Placebos. Maybe you've heard them called sugar pills are harmless substances not always sugar that are used routinely on groups of sick people in experiments. These experiments test the effectiveness of new drugs. One group is given the new drug. The other group is given a placebo and the results are measure. As you might guess some of the people who received the new drug get better.Surprisingly however some of the placebo group also get better. Why. Well it's an interesting question one which doctors can't quite answer some of the group may have gotten better on their own without any treatment at all. But research has shown that the very act of taking a medication that you think will make you better often does make you feel better. Have you ever taken an aspirin and felt better in five minutes. Aspirin doesn't work that fast does it. Basically if you believe you will get better sometimes you do. The history of how doctors and healers have used the mind body connection to cure people is long and interesting but I see that it's time to close.So I have to cover this in the next class. You'll have to hold your questions on this topic till then. Before you go I have some handouts for you concerning the midterm exams next week.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One group is given the new drug.\\nAs you might guess some of the people who received the new drug get better.Surprisingly however some of the placebo group also get better.\\nWhy. Well it's an interesting question one which doctors can't quite answer some of the group may have gotten better on their own without any treatment at all.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"\"\"\n",
    "Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.\n",
    "\n",
    "Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.\n",
    "For surveillance videos, one might want to extract the important events from the uneventful context.\n",
    "\n",
    "There are two general approaches to automatic summarization: extraction and abstraction. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.\\nDocument summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(mytext)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to get list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.',\n",
       " 'Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(mytext,split=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to get ratio of text upto some value like 0.2 or 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.\\nDocument summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words about 50\n",
    "summarize(mytext,word_count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_txt2 = summarize(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_txt2.split()) #####number of words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to find the position of the extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=summarize(mytext,ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t in mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext.find(t)           ###using find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext.index(t)           ###using index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "other method to find location of summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.textcleaner import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.',\n",
       " 'Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.',\n",
       " 'Automatic data summarization is part of machine learning and data mining.',\n",
       " 'The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set.',\n",
       " 'Such techniques are widely used in industry today.',\n",
       " 'Search engines are an example; others include summarization of documents, image collections and videos.',\n",
       " 'Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.',\n",
       " 'For surveillance videos, one might want to extract the important events from the uneventful context.',\n",
       " 'There are two general approaches to automatic summarization: extraction and abstraction.',\n",
       " 'Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary.',\n",
       " 'In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express.',\n",
       " 'Such a summary might include verbal innovations.',\n",
       " 'Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Sentences\n",
    "split_sentences(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_sentences = split_sentences(mytext)              # List of all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t in all_sentences                                      # Is Our Summary in Our List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_sentences.index(t)                                     # Location of our Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.Series(all_sentences)                             ####converting into series to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.DataFrame(a,columns=['sentence'])  ## or  a.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    #Remove RT\n",
    "    #text = re.sub(r'RT', '', text)\n",
    "    \n",
    "    #Fix &\n",
    "    #text = re.sub(r'&amp;', '&', text)\n",
    "    \n",
    "    #Remove punctuations\n",
    "    text = re.sub(r'[?!.;:,#@-]', '', text)\n",
    "\n",
    "    #Convert to lowercase to maintain consistency\n",
    "    #text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['sentence']=s['sentence'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technologies that can make a coherent summary take into account variables such as length writing style and syntax'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "un=all_sentences[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=all_sentences.index(un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_sentences[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.',\n",
       " 'Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.',\n",
       " 'Automatic data summarization is part of machine learning and data mining.',\n",
       " 'The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set.',\n",
       " 'Such techniques are widely used in industry today.',\n",
       " 'Search engines are an example; others include summarization of documents, image collections and videos.',\n",
       " 'Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.',\n",
       " 'For surveillance videos, one might want to extract the important events from the uneventful context.',\n",
       " 'There are two general approaches to automatic summarization: extraction and abstraction.',\n",
       " 'Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary.',\n",
       " 'In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express.',\n",
       " 'Such a summary might include verbal innovations.',\n",
       " 'Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_sentences[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.', 'Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.', 'Automatic data summarization is part of machine learning and data mining.', 'The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set.', 'Such techniques are widely used in industry today.', 'Search engines are an example; others include summarization of documents, image collections and videos.', 'For surveillance videos, one might want to extract the important events from the uneventful context.', 'There are two general approaches to automatic summarization: extraction and abstraction.', 'Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary.', 'In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express.', 'Such a summary might include verbal innovations.', 'Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.']\n"
     ]
    }
   ],
   "source": [
    "if un in all_sentences:\n",
    "    print((all_sentences[:ind])+(all_sentences[ind+1:]))      ###concatenating lists except the choosen sentence printing remaining sentences\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
